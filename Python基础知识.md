### 1、python垃圾回收机制GC

引用计数机制为主，标记-清除、隔代回收两种机制为辅的策略

  ##### （1）计数机制
  
  每一个对象有一个引用计数器，当计数器为0时，说明此对象没有被使用了，将其内存销毁
  
  优点：实时性高，一旦为0，立刻销毁
  
  缺点：为了维护引用计数器，消耗额外资源；无法处理循环引用的问题，循环引用会导致内存泄漏
    
  ##### （2）标记-清除（在 ↑ 的基础上）
  
  关注可能会产生循环引用的对象，如list，tuple，dict（容器对象）
  
  GC会把所有活动对象打上标记，可以看做点，引用关系构成边，即成为有向图
  
  从根对象root出发，沿着有向边出发，遍历不到的和存在环的就是需要清除的
  

  ##### （3）隔代回收（在 ↑ 的基础上）
  
  以空间换时间
  
  根据内存中对象的存活时间将其分为3代，新生对象放到0代，如果从0代垃圾回收活下来，变成1代，如此循环直到2代
  

### 2、进程、线程（底层）


Python并发编程：串行 → 并行，提升执行效率

最终是线程在工作，多个线程组成一个进程，py文件运行时候，创建一个进程（主进程），进程创建一个线程（主线程）

##### （1）线程

    计算机中，能被 CPU 调度的最小单元
    
    ```
    import threading  # 多线程库

    t=threading.Thread(target=函数名，args=(11,22,33))  # 其中，后面几个数字是函数的参数
    t.start（） # 让线程开始工作

    ```

    
##### （2）进程（资源消耗比较多）

    计算机资源分配的最小单元，为线程提供资源的单位
    
    ```
    import multiprocessing  # 多进程包
    
    t=multiprocessing.Process(target=函数名，args=(11,22,33))
    t.start()
    
    ```
##### （3）GIL锁（全局解释器锁）

    保证一个进程中同一时刻只有一个线程可以被CPU调用
    
    所以在多核CPU的计算机下，在GIL锁下，则需要变成多进程并发，才能高并发
    
    高I/O的请求：不太需要CPU，可以多线程
    
    高计算的请求：需要CPU，且因为有GIL锁，用多进程
    
    列表、字典等的线程安全就是得益于GIL锁------------------------------------
    
 ##### （4）线程安全
 
    多个线程同时操作一个东西时候，可能会产生线程不安全，因为线程同步运行
    
    （官方一点解释：处理数据有概率有交集 ↑ ）
    
    解决方法：手动加锁（线程锁）（加在函数里面）
    
    细节：这几个线程要用同一把锁才行，一把锁一个时间只会有一个线程在用
    
    
    有些数据类型是线程安全的（本身自带锁）：list、dict类型.....
    
    
### 3、线程锁（常见两种）

申请锁释放锁是要耗费性能的！！！！！

ps：直接用with 锁名称：

下面继续写代码，则自动执行申请、释放，方便一点

##### （1）Lock 同步锁

    不支持锁的嵌套，一嵌套：死锁

##### （2） RLock 递归锁

    这个支持，其他的和 Lock 一样
    
### 4、线程池

线程开太多了，反而可能性能下降（线程之间的上下文切换）

解决方法：用线程池

```

from concurrent.futures import ThreadPoolExecutor

pool=ThreadPoolExecutor（100）

pool.submit(函数名，参数1，参数2.........)  # 由线程池来安排给这个任务的线程

```




### 5、死锁

https://blog.csdn.net/shanniuliqingming/article/details/120926413?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165720147516780357217689%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=165720147516780357217689&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120926413-null-null.142^v32^down_rank,185^v2^control&utm_term=Python%20threading&spm=1018.2226.3001.4187

Lock嵌套了：死锁

线程互相竞争多把锁（一个线程握了一个其他线程需要的锁）：死锁（即：互锁造成的）



### 6、byte数据结构

### 7、深拷贝、浅拷贝

### 8、装饰器

### 9、pytorch优化器区别

### 10、python的一些自动化框架包

### 11、with 上下文管理

    完成自动加锁、释放锁功能？

### 12、单例模式

  单例模式：每次对类实例化，都用一个对象，不再新创建对象
  
  在多线程下-可能-会出问题
  
  可用加锁解决！！！！！！！！！！！！！！！！！！！！！！！

### 13、闭包

### 14、list、tuple、dict....区别

### 15、*args,**kwargs 目的

    这俩是Python方法中的可变参数
    
    -----------------用于方法参数不确定的时候----------------------------
    
    （1）*args 表示任何多个无名参数，是一个元组tuple
    
    （2）**kwargs 表示关键字参数，是一个dict

### 16、Python类cls

一般来说，要使用某个类的方法，需要先实例化一个对象再调用方法

cls在python中表示类本身，self为类的一个实例

```
class F:

  __init__（self,参数1,参数2....）

  __new__(cls,*arg2,**kwargs)

```

在这其中，先执行new，创建实例化对象，再用__init__进行初始化

### 17、多进程开发详解

```
    p=multiprocessing.Process(target=函数名，args=(11,22,33))
    
    p.start()
    
    p.join() # 等待子进程（中的子线程）执行完毕，再继续进行主进程（中的主线程的执行）
```

##### （1）进程之间数据共享
  
  a.用with manage进行管理
  
  b.用队列实现
  
  c.pipes 用管道实现
  
  现实应用中，一般借助其他三方库来实现， 比如MySQL，redis
  
##### （2）进程锁

    一个程序的多个进程共享一个资源的时候，需要加锁
    
    进程锁可以当做参数传进创建进程中（主进程里创建了这把锁，然后当参数传入子进程，此时所有进程共享一把锁），线程锁不行！！！！！！
    
    
##### （3）进程池

from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor
    
--------concurrent模块--------
    

